\chapter{Project Proposal}

\newcommand{\dontcite}[1]{}

\textit{The following is quoted verbatim. However, formatting and citations were adjusted to be consistent with the rest of this document.}

\section{Introduction}

Tensors are an ubiquitous abstraction in the area of machine learning. In this context, they are $n$-dimensional arrays specialised for high-performance data parallel computing. The Python programming language dominates the machine learning research scene. However, its runtime overheads are far too high for the data processing to be expressed directly in the language. As such, Python highly benefits from the tensor abstraction with a set of highly optimised operations. This gave rise libraries and frameworks such as NumPy \cite{harris2020array}, PyTorch and TensorFlow.

These aforementioned libraries all share a common core of the \textit{array programming model}, as introduced in APL \cite{iverson1962programming}. The model is characterised by first-class multi-dimensional arrays. Primitives are parameterised in nontrivial ways, acting on the arrays as a whole -- individual elements are rarely referenced. The core benefit of this approach is that the implementations of individual primitives -- referred to as \textit{kernels} -- can be highly optimised (and written in another language). Programs in the model can also be surprisingly concise, as can be seen on Figure \ref{fig:pairwise-l1-numpy}. 

\begin{figure}[h]
    \centering
    \begin{minipage}{0.65\textwidth}
    \begin{minted}{python}
def pairwiseL1(a):
    return sum(abs(a.T - a[..., newaxis]), axis=1) 
    \end{minted}
    \end{minipage}
    \caption{Computing a matrix of pairwise $L_1$ distances between rows with axis manipulation and broadcasting in NumPy -- as given by Dex authors \cite{maclaurin2019dex}}
    \label{fig:pairwise-l1-numpy}
\end{figure}

Despite its widespread use in today's scientific computing and machine learning workflows, the array programming model is not without its problems. The available operations expose features such as broadcasting, which allow high expressiveness without sacrificing performance. However, these features also make programs difficult to write, debug and maintain \cite{paszke2021getting}. They are also nontrivial to statically analyse due to being highly dynamic, as the behaviour of operators may vary based on the shapes and element types of their inputs \dontcite{liu2020type}. This causes the need for comments in the host language, as few facilities exist for type annotations \dontcite{Rush2018}. Additionally, the actual implementation in terms of the available kernels may be distant from the mathematical description of a computation -- as can be seen in Figure \ref{fig:pairwise-l1-math}. The choice of kernels is not obvious, as their number is usually in the hundreds. More involved pieces of logic have to be expressed with more specialised kernels (if they exist), or otherwise complex  combinations of existing ones (suboptimal performance), or worst of all expressed directly in Python, which significantly hurts performance.

\begin{figure}[h]
    \centering
    $$ \texttt{pairwiseL1}(A)_{i,j} = \sum_{k} \left| A_{i,k} - A_{j,k} \right|  $$
    \caption{An index-oriented mathematical formulation of \texttt{pairwiseL1} from Figure \ref{fig:pairwise-l1-numpy}}
    \label{fig:pairwise-l1-math}
\end{figure}

All in all, these shortcomings cause novel deep learning architectures to be unreasonably difficult to express and optimise in the array programming model. This invites the exploration of new array programming paradigms which seek to solve these problems.

Dex \cite{paszke2021getting} is a recent research programming language implementing \textit{pointful} (or \textit{index-oriented}) array programming, which can be seen as a generalisation of \textit{Einstein summation notation}. Its distinctive feature is the \texttt{for} primitive, where an array's elements may be defined in terms of their indices. Programs written with this approach boast closeness to mathematical notation (Figure \ref{fig:pairwise-l1-dex}). Index bounds are inferred as in Einstein summation for clarity. Dependent types fulfil a central role for statically analysing array sizes. Dex demonstrates that the paradigm can achieve performance comparable to other approaches, such as the \textit{array-combinator} language Futhark \cite{henriksen2017futhark}.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.6\textwidth}        
    \begin{minted}{haskell}
def pairwiseL1 (a : m=>n=>Float) : n=>n=>Float =
    for i. for j. sum for k. abs (a.i.k - a.j.k) 
    \end{minted}
    \end{minipage}
    \caption{Computation of \texttt{pairwiseL1} from Figure \ref{fig:pairwise-l1-numpy} in Dex}
    \label{fig:pairwise-l1-dex}
\end{figure}

However, application of an entirely new language like Dex poses further problems, such as its usability in the existing ecosystem. Embedding the DSL \cite{gibbons2014folding} is a popular approach to address this. Jax \cite{frostig2018compiling} can be seen as a domain-specific language within a shallow embedding in Python. Operations performed on Jax arrays are \textit{traced} into a staged expression. That IR can then be e.g. differentiated, and compiled for execution via XLA \dontcite{jax2018github}. This approach is in contrast to the deep embeddings used in TensorFlow and PyTorch, which manipulate the Python AST. Shallow embeddings are generally better composable and more predictable.

\section{Description}

The main goal of the project is to design and implement a pointful array programming domain-specific language in a shallow Python embedding, lending itself to being easy to use, statically analyse, and execute efficiently.

The basis of the DSL would be formed by an underlying calculus -- provisionally named \textit{Ein}~and~\textit{Phi} respectively. Phi could be based on the semantics of Dex. A proposed basic version of this calculus is shown in Figure \ref{fig:phi-calculus}. Its core feature is vector comprehensions -- defining tensors in terms of their elements as functions of indices. It is not an aim for the core language to include all Dex features such as algebraic effects and dependent types, though similar ideas can be developed as extensions. Phi can be extended with more arithmetic functions and reductions (like product).

\begin{figure}[h]
    \centering
    \begin{align*}
        e ::=& \quad \Phi\, i[e].\, e & \text{(vector comprehension)} \\
        |& \quad \Sigma\, i[e].\, e  & \text{(vector summation)} \\
        |& \quad e[e]  & \text{(indexing)} \\
        |& \quad e + e \quad | \quad e \cdot e \quad | \quad e - e \quad | \quad e \mathop{/} e   & \text{(scalar arithmetic)} \\
        |& \quad i \quad | \quad x &\text{(index value, variable)}
    \end{align*} 
    $$ \texttt{pairwiseL1}(a) = \Phi \,i[n].\, \Phi \,j[n].\, \Sigma\, k[m].\,
    \texttt{abs}\left( a[i][k] - a[j][k] \right) $$
    \caption{Proposed structure of the Phi calculus. Below an example term is given, where $a$ has shape $n \times m$. All three variables are given in scope.}
    \label{fig:phi-calculus}
\end{figure}
A computation in Ein should be traced, and then staged for execution by a \textit{backend}. As NumPy is universally available and has good performance on CPU, it is planned to be the primary backend. Hence, a core part of the project is compilation of expressions in the DSL to an efficient sequence of NumPy calls necessary to execute it.

Though Python is the host language, compilation can happen in another language -- for instance Rust, as it interfaces well with Python via PyO3 \dontcite{PyO3} and is better suited for compiler-related tasks with static types and ADTs. I plan to resolve this in early stages of the project.

\begin{figure}[h]
    \centering
    \begin{minted}{python}
n, m = a.shape
# tensor and sum are primitives in Ein, corresponding to phi and sigma in Phi
dist = tensor[n, n](lambda i, j: sum[m](lambda k: abs(a[i, k] - a[j, k])))
# dist may be computed with NumPy arrays:
x = a.reshape(n, 1, m)  # x[i, *j, k] = a[i, k]
y = a.reshape(1, n, m)  # y[*i, j, k] = a[j, k]
z = x - y               # z[i, j, k] = a[i, k] - a[j, k]
w = z.abs()             # w[i, j, k] = abs(a[i, k] - a[j, k])
dist = w.sum(axis=2)    # dist[i, j] = sum(k: abs(a[i, k] - a[j, k]))
\end{minted}
    \caption{Code example in Ein, along with a sequence of NumPy calls for executing it.}
    \label{fig:pairwise-l1-ein}
\end{figure}

\needspace{1em}
\section{Starting point}

I have no experience designing or implementing a machine learning domain-specific language or compiler. I expect the knowledge from Part IB Semantics, Compiler Construction and Concepts courses will be useful during design and development, and that the Part II Denotational Semantics and Types may also be helpful when working on extensions to the semantics and type system of the language. Part IA Scientific Computing and Part IB Data Science gave me an insight into array programming in NumPy itself, though I have also used NumPy in personal projects.

I have been exposed to the domain of machine learning during my open-source work on the ONNX project, which is an industry standard IR for describing models. Working on a research project on Graph Neural Networks during Part IB has also given me some domain experience. I have years of Python experience, including professional, and basic experience with Rust.

Prior to starting the project I had done a fair amount of research into the topic of array programming, including papers on index-oriented techniques and compiler optimisations relevant to linear algebra and machine learning. I had not written any project-specific code before 1~October, though I have written experiments to test the feasibility of some of the ideas.

\section{Goals}

\subsection{Core}

\paragraph{Formalisation} Design and formalise operational semantics of a calculus for expressing pointful array programming. A basic type system (up to tensor element type and rank) to validate these terms should be given. These may be based on a subset of the rules presented in Paszke et al. \cite{paszke2021getting}.

\paragraph{Embedding} Implement a Python API for constructing Phi calculus terms, forming Ein. The terms should be easy to serialise, to make way for tooling developed in other languages.

\paragraph{Execution} Create a NumPy execution backend for evaluating Phi expressions. The computation should be orchestrated into a sequence of necessary calls.

\paragraph{Testing} Collate an Ein test and benchmark suite, based on the ones in Dex and Futhark. Results should be compared to NumPy implementations in terms of correctness and performance.

\subsection{Extensions}

\paragraph{Optimisation} The terms in the calculus benefit from relative expressiveness, and their purity makes them easy to manipulate. Many optimisations could be derived with equality saturation \dontcite{10.14778/3407790.3407799}, for instance as implemented in the egg library \dontcite{2021-egg}. A focus would be on optimisations which are not performed by existing frameworks, for instance in linear algebra \dontcite{9835658}. This may also include loop fusion, finding common subexpressions (up to arrays), and axis ordering.

\paragraph{Backends} Execution with different compatible frameworks in the style of Einops \cite{rogozhnikov2021einops} is a large benefit which allows using the DSL within an existing project -- for instance one employing PyTorch or Jax. These are relatively similar to NumPy, and so the implementation should be as well. In the direction of a classical compiler, implementing C code generation or compiling directly with LLVM is also possible for portability and slightly better performance. Lastly, state-of-the-art deep learning compilers like XLA \dontcite{50530} or TVM \dontcite{10.5555/3291168.3291211} could be used directly.

\paragraph{Types} Dynamic sizes in array types are difficult to design types for. Possible solutions include a unification-based approach with existential types \dontcite{Abe2015ASA}, or Futhark's size-dependent types \cite{henriksen2021towards}. Advanced static analyses could be done with an SMT solver like Z3 \dontcite{2008-z3}. Another direction is basic parametric polymorphism for numeric types in the style of Haskell's \texttt{Num} and \texttt{Floating} typeclasses. 

\paragraph{Further expressiveness} Capabilities like domain-specific intrinsics (e.g. matrix inverse), allowing usage of sequential loops or jagged arrays, and custom reductions (besides summation).

\paragraph{Program transformation} Ranges from basic syntactic sugar for inferring index bounds deriving from Einstein summation, up to automatic differentiation (forward or backward) which may base on the approach in Dex \cite{paszke2021getting} or Jax \cite{frostig2018compiling}. 

\section{Success criteria}

\begin{itemize}
    \item Presenting a design of the Phi pointful array calculus. An integral part is definition of tensors with their elements defined in terms of their indices, as in Dex \cite{paszke2021getting}.
    \item A shallow embedding of the Ein DSL in Python, with an API that constructs Phi calculus terms via tracing. The technique may draw on Jax \cite{frostig2018compiling}.
    \item Implementation of an execution backend for Ein, which compiles the terms into a form that may leverage libraries in the Python ecosystem.
    \item An evaluation of correctness, performance and expressiveness of Ein.
\end{itemize}

\section{Evaluation strategy}


The evaluation would be performed on a test and benchmark suite derived from the ones in existing projects -- such as Dex \cite{paszke2021getting} and Futhark \cite{henriksen2017futhark}. They themselves are based on other existing suites like Parboil \dontcite{Stratton2012ParboilAR}. Other sources of program samples include modern deep learning model architectures, like transformers or graph neural networks.
\paragraph{Correctness} The test suite can be used to demonstrate general correctness of the language. If an execution backend is not trivially derived from the operational semantics, a formal proof of correctness may also be given.

\paragraph{Performance} Performance should be comparable to existing approaches when the code is casually written without additional care given to performance. Reaching state-of-the-art performance is not within the scope of the project.

\paragraph{Expressiveness} Successful creation of a representative test suite will demonstrate the expressiveness of the language. It should be noted that instances of sequential logic (where usage of control flow primitives like algebraic effects in Dex or \texttt{loop} in Futhark is necessary) are considered an extension. This is motivated by their relative rarity in deep learning frameworks, where they are seldom the focus of optimisation.

% \paragraph{Usability} The language should present a higher degree of code readability than in frameworks employing the array programming model on an example in the target domain, such as an implementation of an attention layer (or another one present in the benchmark suite). An absence of axis indexing and self-documenting through index names are considered pluses \cite{Rush_2018}.

\section{Timetable}

\subsection{Michaelmas Term}

\begin{itemize}
    \item \textbf{Weeks 2 -- 4} (October \nth{12} -- November \nth{1})  \begin{itemize}
        \item Review literature on tensor languages and index-oriented approaches, particularly Dex.
        \item Construct the semantics and type system of Phi.
        \item Ensure the type system meets required properties, formulate a Progress theorem.
        \item \textbf{Milestone.} Formal pointful array programming calculus as a basis for Ein.
    \end{itemize}
    \item \textbf{Weeks 5 -- 6} (November \nth{2} -- November \nth{15}) 
 \begin{itemize}
        \item Implement an API for constructing Phi calculus terms.     
        \item Create a fundamental backend for evaluating terms in pure Python without the usage of an array library.
        \item Construct small correctness test cases suitable for the basic backend.
        \item \textbf{Milestone.} Ein embedded in Python with basic evaluation.
    \end{itemize}
    \item \textbf{Weeks 7 -- 8} (November \nth{16} -- November \nth{29}) \begin{itemize}
        \item Design the NumPy execution backend and construct a term evaluation algorithm.
        \item Prove the correctness of term evaluation under reasonable assumptions.
        \item Implement the NumPy staging and execution backend.
        \item \textbf{Milestone.} NumPy execution backend passing basic tests.
    \end{itemize}
\end{itemize}

\subsection{Michaelmas Vacation}

\begin{itemize}
    \item \textbf{Weeks 1 -- 3} (November \nth{30} -- December \nth{20}) \begin{itemize}
        \item Collate a test and benchmark suite from the Futhark, Dex and other codebases.
        \item Based on testing feedback, fix and improve on the NumPy backend.
        \item \textit{Extensions.} Implement syntactic sugar (e.g. bounds inference) to ease writing the suite. 
        \item \textbf{Milestone.} NumPy execution backend tested and effective.
    \end{itemize}

    \item \textbf{Weeks 4 -- 5} (December \nth{21} -- January \nth{3}) -- Break for Christmas.

    \item \textbf{Weeks 6 -- 7} (January \nth{4} -- January \nth{17}) \begin{itemize}
        \item Test, refactor and document the existing code.
        \item Finish and improve any core steps.
        \item Begin work on progress report.
        \item \textbf{Milestone.} \textit{Success criteria met.}
    \end{itemize}
\end{itemize}

\subsection{Lent Term}

\begin{itemize}
    \item \textbf{Weeks 1 -- 2} (January \nth{18} -- January \nth{31})  \begin{itemize}
        \item Write the progress report and start work on slides.
        \item \textit{Extensions.} Preparatory work and determining feasibility. Attempt evaluation of real-world deep learning model within the DSL. Implement support for intrinsics like linear algebra routines.
        \item \textbf{Milestone.} Progress Report [February 2].
    \end{itemize}
    \item \textbf{Weeks 3 -- 4} (February \nth{1} -- February \nth{14})  \begin{itemize}
        \item Prepare slides for presentation.
        \item \textit{Extensions.} Implement and evaluate backends using a deep learning framework (PyTorch/Jax) and another using code generation (C/LLVM)
        \item \textbf{Milestone.} Progress Report Presentation [February \nth{7} -- February \nth{14}].
    \end{itemize}
    \item \textbf{Weeks 5 -- 6} (February \nth{15} -- February \nth{28}) \begin{itemize}
        \item Dissertation -- Write Chapter 1: Introduction \& Chapter 2: Preparation.
        \item \textit{Extensions.} Experiment with optimisations using equality saturation on one of the existing backends.
    \end{itemize}
    \item \textbf{Weeks 7 -- 8} (February \nth{29} -- March \nth{13}) \begin{itemize}
        \item Dissertation -- Write Chapter 3: Implementation.
        \item \textit{Extensions.} Investigate and attempt an approach to size types.
    \end{itemize}
\end{itemize}

\subsection{Easter Vacation}

\begin{itemize}
    \item \textbf{Weeks 1 -- 2} (March \nth{14} -- March \nth{27})  \begin{itemize}
        \item Dissertation -- Write Chapter 4: Evaluation.
        \item \textit{Extensions.} Finalise the scope and implementation.
    \end{itemize}
    \item \textbf{Weeks 3 -- 4} (March \nth{28} -- April \nth{10})  \begin{itemize}
        \item Dissertation -- Write Chapter 5: Conclusions.
        \item Share full draft with supervisor and directors of studies. 
        \item \textbf{Milestone.} Full dissertation draft shared for review.
    \end{itemize}
    \item \textbf{Weeks 5 -- 6} (April \nth{11} -- April \nth{24})  \begin{itemize}
        \item Address review comments for draft.
        \item \textbf{Milestone.} Reviewed dissertation draft.
    \end{itemize}
\end{itemize}

\subsection{Easter Term}

\begin{itemize}
    \item \textbf{Weeks 1 -- 2} (April \nth{25} -- May \nth{8}) \begin{itemize}
        \item Editing and proofreading dissertation.
        \item Updating dissertation with latest results from extensions.
        \item Prepare source code for submission.
        \item \textbf{Submission [May \nth{10}]}
    \end{itemize}
\end{itemize}

\section{Resource declaration}

I will use my personal laptop (2021 MacBook Pro, 14-inch) for developing the project. I accept full responsibility for this machine and I have made contingency plans to protect myself against hardware and/or software failure. GitHub will be used to backup the repository and project notes, and Overleaf will be used for the dissertation itself. These are in addition to backups on my other personal devices. All libraries and packages used will be open-source. As part of extensions, I may make use of an external computing cluster, such as the freely available Google Colab or department resources.
